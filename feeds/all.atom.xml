<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>jackson.gs</title><link href="jackson.gs/" rel="alternate"></link><link href="jackson.gs/feeds/all.atom.xml" rel="self"></link><id>jackson.gs/</id><updated>2014-05-27T19:42:00+10:00</updated><entry><title>CS109 lecture three</title><link href="jackson.gs/cs109-lecture-three.html" rel="alternate"></link><updated>2014-05-27T19:42:00+10:00</updated><author><name>jacksongs</name></author><id>tag:jackson.gs,2014-05-27:cs109-lecture-three.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Never stop learning is a motto of mine. &lt;a href="/dabbling-in-data-science.html"&gt;Here&lt;/a&gt; it's data science, and &lt;a href="http://cs109.org/"&gt;Harvard's CS109 data science course&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://cm.dce.harvard.edu/2014/01/14328/S01/index_H264SingleHighBandwidth-16x9.shtml"&gt;first lab&lt;/a&gt; was pretty basic Python, and didn't include much of the array-based computing techniques I'm looking for. &lt;/p&gt;
&lt;p&gt;The readings for week one were also fairly preliminary and were mostly covered in the lectures.&lt;/p&gt;
&lt;p&gt;So onward it is to the second week...&lt;/p&gt;
&lt;h1&gt;Lecture three notes - &lt;a href="http://cm.dce.harvard.edu/2014/01/14328/L03/index_H264SingleHighBandwidth-16x9.shtml"&gt;video link&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;15:25 - Edward Tufte.&lt;/p&gt;
&lt;p&gt;16:10 - Key principle of Tufte:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Graphical integrity, spatial distortions, ie bar graphs always start at zero. (reference to How to Lie with Statistics). For line graphs, scale distortions are more acceptable, though reader should be alerted.&lt;/li&gt;
&lt;li&gt;Show context, ie don't be selective with data. But need to be a little bit selective. &lt;/li&gt;
&lt;li&gt;Avoid lie factor, based on size of effect in graphic/size of effect in data.&lt;/li&gt;
&lt;li&gt;Data ink ratio maximised, ie data ink/total ink used in graphic.&lt;/li&gt;
&lt;li&gt;Avoid chartjunk, but matplotlib defaults are awful! Check out IPython notebook in reading.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;32:30 - Chart types. Start by asking:&lt;/p&gt;
&lt;h2&gt;Comparisons?&lt;/h2&gt;
&lt;p&gt;Bar chart, look at Chris' notebook&lt;/p&gt;
&lt;p&gt;For long labels, rotate bars 90 degrees&lt;/p&gt;
&lt;h2&gt;Trends over time?&lt;/h2&gt;
&lt;p&gt;Line charts are reliable&lt;/p&gt;
&lt;p&gt;Important that x-axis is continuous variable&lt;/p&gt;
&lt;p&gt;But! Bars vs lines: lines imply continuous data points.&lt;/p&gt;
&lt;p&gt;Consider aspect ratio. Look at average slope... we are tuned for comparing lines at about 45 degrees.&lt;/p&gt;
&lt;h2&gt;Correlations?&lt;/h2&gt;
&lt;p&gt;Consider light grey border for plotting dots in crowded scatter plots.&lt;/p&gt;
&lt;p&gt;Overplotting problems, try grey borders and muted colours. Or try opacity changes.&lt;/p&gt;
&lt;p&gt;Add a trend line for scatter plots along with confidence intervals.&lt;/p&gt;
&lt;h2&gt;Compositions?&lt;/h2&gt;
&lt;p&gt;Pie chart is used most often here, even though people hate them.&lt;/p&gt;
&lt;p&gt;Some advantages. Ie showing how two categories add up - bar chart is less effective.&lt;/p&gt;
&lt;p&gt;Labelling and order by size is important.&lt;/p&gt;
&lt;p&gt;But consider bar unless there is good reason.&lt;/p&gt;
&lt;p&gt;Donut charts lost the middle piece, the angle, which helps with comparisons.&lt;/p&gt;
&lt;p&gt;What about stacked bar graph? Or 100% bar graph. These are pretty good, arguably better than pie charts.&lt;/p&gt;
&lt;p&gt;But, the problem is when you want to compare segments that aren't lined up on the x-axis.&lt;/p&gt;
&lt;p&gt;Small multiples are also very handy.&lt;/p&gt;
&lt;p&gt;Stacked area chart/100% stacked area chart.&lt;/p&gt;
&lt;p&gt;But - combined line chart is usually better.&lt;/p&gt;
&lt;h2&gt;Distributions?&lt;/h2&gt;
&lt;p&gt;Histogram - play with the bin size.&lt;/p&gt;
&lt;p&gt;Density plots - you could also show the raw data in dots along the axis.&lt;/p&gt;
&lt;p&gt;Heat maps - 2d version of heatmap.&lt;/p&gt;
&lt;p&gt;Box and whisker plots. Red line - median. Box - 25/75 percentile. Whiskers - max/min or 5/95 percentile.&lt;/p&gt;
&lt;h2&gt;Colour&lt;/h2&gt;
&lt;p&gt;Sometimes required - eg maps with quantitative info, if you already have used 2 spatial dimensions use colour for 3rd dimension, categories in line charts or bar charts.&lt;/p&gt;
&lt;p&gt;3 dimensions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;lightness&lt;/li&gt;
&lt;li&gt;hue&lt;/li&gt;
&lt;li&gt;saturation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nominal data or categories suits colours well.&lt;/p&gt;
&lt;p&gt;Ordinal data suits the lightness spectrum.&lt;/p&gt;
&lt;p&gt;For quantitative data, don't use colour map!&lt;/p&gt;
&lt;p&gt;Why? Hard to order. But also chroma channel has lower resolution than lightness channel. And also it is perceptually non-uniform: ie for a uniform change, changes in colour look like there are small jumps.&lt;/p&gt;
&lt;p&gt;Instead, use Brewer scales. See ColorBrewer website. And see Chris' IPython notebook for examples in Python.&lt;/p&gt;</summary><category term="harvard"></category><category term="python"></category><category term="cs109"></category></entry><entry><title>CS109 lecture two</title><link href="jackson.gs/cs109-lecture-two.html" rel="alternate"></link><updated>2014-05-25T20:42:00+10:00</updated><author><name>jacksongs</name></author><id>tag:jackson.gs,2014-05-25:cs109-lecture-two.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Never stop learning is a motto of mine. &lt;a href="/dabbling-in-data-science.html"&gt;Here&lt;/a&gt; it's data science, and &lt;a href="http://cs109.org/"&gt;Harvard's CS109 data science course&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;Week 1, lecture 2 notes - &lt;a href="http://cm.dce.harvard.edu/2014/01/14328/L02/index_H264SingleHighBandwidth-16x9.shtml"&gt;video link&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Here are some notes from the second lecture video in week one.&lt;/p&gt;
&lt;h2&gt;Outline:&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Process and process books
&lt;/em&gt;Effective visualisations
*Data sources and cleanup&lt;/p&gt;
&lt;p&gt;11:20 - AGEMC! Ask, get, explore, model, communicate. Plus loops between them.&lt;/p&gt;
&lt;p&gt;12:20 - 'What do analysts do paper?' - This is part of the readings, should be good reading.&lt;/p&gt;
&lt;p&gt;13:50 - Most of time spent? Prepping the data!&lt;/p&gt;
&lt;p&gt;14:50 - Process of data science not yet codified in these companies. Interesting... Repeatability, documentation, process are all critical.&lt;/p&gt;
&lt;p&gt;16:20 - Data cleanup and knowing your data is very important. John Tukey: exploratory data analysis. Look at the data visually before you formulate hypotheses.&lt;/p&gt;
&lt;p&gt;17:35 - Anscombe's Quartet: artificial datasets that have same mean, variance, correlation and linear regression line.&lt;/p&gt;
&lt;p&gt;18:30 - Antibiotic example. Will Burtin, 1951. Data and questions. Talking data types: strings, floats, booleans.&lt;/p&gt;
&lt;p&gt;29:30 - Bacteria comparison example. Key learning: think of more interesting questions, for example consider categories.&lt;/p&gt;
&lt;p&gt;31:15 - "That's funny..." is a cue to pursue more and better informed questions.&lt;/p&gt;
&lt;p&gt;32:00 - Process book! Suits the static blog very well with IPython notebooks.&lt;/p&gt;
&lt;p&gt;35:30 - IPython notebook demonstrations.&lt;/p&gt;
&lt;p&gt;41:40 - Good coding practices: commenting, modularity, array-oriented computing, using assert statements and tests, version control. Array-oriented computing will need some work! (No more for/while loops.) &lt;/p&gt;
&lt;h2&gt;Data types&lt;/h2&gt;
&lt;p&gt;Starts 46:54&lt;/p&gt;
&lt;p&gt;Ben Shneiderman, 1996, different types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sequences (1D)&lt;/li&gt;
&lt;li&gt;temporal&lt;/li&gt;
&lt;li&gt;2d (maps)&lt;/li&gt;
&lt;li&gt;3d (shaped)&lt;/li&gt;
&lt;li&gt;nD (relational) - ie table&lt;/li&gt;
&lt;li&gt;trees (hierarchical)&lt;/li&gt;
&lt;li&gt;networks (graphs)&lt;/li&gt;
&lt;li&gt;others?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tamara Munzner, 2013, simpler:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tables&lt;/li&gt;
&lt;li&gt;networks&lt;/li&gt;
&lt;li&gt;text/logs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Semantics (meaning) vs types (interpretation in terms of scale of measurement)&lt;/p&gt;
&lt;p&gt;1946, Stevens paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nominal (a thing, equal or not equal, but little else)&lt;/li&gt;
&lt;li&gt;ordinal (obey size relationships)&lt;/li&gt;
&lt;li&gt;quantitative (can be interval or ratio)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Operations therefore:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nominal: =&lt;/li&gt;
&lt;li&gt;ordinal: =,&amp;gt;&lt;/li&gt;
&lt;li&gt;interval: =,&amp;gt;,+ (distance)&lt;/li&gt;
&lt;li&gt;ratio: =,&amp;gt;,+,x (proportions)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Row = item
Column = attribute or feature&lt;/p&gt;
&lt;p&gt;Nominal/Ordinal = Dimensions
Quantitative = Measures&lt;/p&gt;
&lt;h2&gt;Data dimensions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Univariate - lots of chart options&lt;/li&gt;
&lt;li&gt;Bivariate - scatter only really (not 3D! Use size/colour instead)&lt;/li&gt;
&lt;li&gt;Multivariate - tables of many columns (consider small multiples, but this is a big challenge in data visualisation)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So focus on data reduction...&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Filtering - select of interest
&lt;/em&gt;Aggregation - ave, min, max&lt;/p&gt;
&lt;h2&gt;Mapping data to images&lt;/h2&gt;
&lt;p&gt;Jacques Bertin, French Cartographer, 'Semiology of Graphics' 1967 provided a basic vocabulary of marks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Points&lt;/li&gt;
&lt;li&gt;Lines&lt;/li&gt;
&lt;li&gt;Zones&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Along with channels:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Position&lt;/li&gt;
&lt;li&gt;Size&lt;/li&gt;
&lt;li&gt;Greyscale&lt;/li&gt;
&lt;li&gt;Texture&lt;/li&gt;
&lt;li&gt;Colour&lt;/li&gt;
&lt;li&gt;Orientation&lt;/li&gt;
&lt;li&gt;Shape&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;William Playfair came up with most types of chart in the late 18th century.&lt;/p&gt;
&lt;p&gt;So what channels/marks are most effective for what data types?&lt;/p&gt;
&lt;p&gt;Colour hue is not perceived as ordered, though brightness and saturation do.&lt;/p&gt;
&lt;p&gt;Bertin set out how well each channel works with data.&lt;/p&gt;
&lt;p&gt;Cleveland/McGill, 1984 and Mackinlay, 1986 carried out studies to check how well people could judge quantities.&lt;/p&gt;
&lt;p&gt;Scale of efficiency:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;position&lt;/li&gt;
&lt;li&gt;length&lt;/li&gt;
&lt;li&gt;slope or angle&lt;/li&gt;
&lt;li&gt;area&lt;/li&gt;
&lt;li&gt;intensity&lt;/li&gt;
&lt;li&gt;colour or shape (but good for nominal types/categories)&lt;/li&gt;
&lt;/ul&gt;</summary><category term="harvard"></category><category term="python"></category><category term="cs109"></category></entry><entry><title>CS109 lecture one</title><link href="jackson.gs/cs109-lecture-one.html" rel="alternate"></link><updated>2014-05-24T16:42:00+10:00</updated><author><name>jacksongs</name></author><id>tag:jackson.gs,2014-05-24:cs109-lecture-one.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Never stop learning is a motto of mine. &lt;a href="/dabbling-in-data-science.html"&gt;Here&lt;/a&gt; it's data science, and &lt;a href="http://cs109.org/"&gt;Harvard's CS109 data science course&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;Week 1 lecture notes - &lt;a href="http://cm.dce.harvard.edu/2014/01/14328/L01/index_H264SingleHighBandwidth-16x9.shtml"&gt;video link&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Here are some notes from the first week lecture video.&lt;/p&gt;
&lt;p&gt;0:40 - Joe Blitzstein gets an ovation from the students. I Google Joe. I still don't get it. Then he mentions Nate Silver. I've read The Signal and the Noise. I can't remember Joe.&lt;/p&gt;
&lt;p&gt;5:00 - Discussing human elements and visualisation. This appeals to me more than the predictive modelling.&lt;/p&gt;
&lt;p&gt;6:10 - The cross-disciplinary nature of data science is exciting.&lt;/p&gt;
&lt;p&gt;7:30 - Shlomo Aragmon quote is pretty good. Must Google that guy too.&lt;/p&gt;
&lt;p&gt;7:50 - Nate Silver. Yeah, yeah.&lt;/p&gt;
&lt;p&gt;12:20 - William Chen. He must be famous (must Google).&lt;/p&gt;
&lt;p&gt;14:15 - "Real data are...". Mmmm. Still not convinced.&lt;/p&gt;
&lt;p&gt;15:50 - Wouldn't mind seeing a chart of Nate Silver references in this lecture. I hope this is the high point.&lt;/p&gt;
&lt;p&gt;17:15 - "Prediction is hard, especially about the future." Heh.&lt;/p&gt;
&lt;p&gt;19:00 - Joe's stutter is gone.&lt;/p&gt;
&lt;p&gt;25:37 - The sequencing chart is pretty amazing. Unfortunately I know nothing about sequencing.&lt;/p&gt;
&lt;p&gt;28:20 - Netflix recommendation engine contest. I'm not necessarily convinced about the obsession around recommendations in media today. But that's for another time.&lt;/p&gt;
&lt;p&gt;31:00 - "How good is this?" Measuring success in data science is difficult. Sounds like swagger might have some significance.&lt;/p&gt;
&lt;p&gt;33:00 - Curse of dimensionality sounds like a good script.&lt;/p&gt;
&lt;p&gt;35:30 - 10% on Netflix prize... conspiracy?&lt;/p&gt;
&lt;p&gt;36:30 - Ramon y Cajal drawings are amazing.&lt;/p&gt;
&lt;p&gt;40:00~ - Yeah that brain stuff was pretty extraordinary. Data science seems to only be a very small part of that though.&lt;/p&gt;
&lt;p&gt;43:20 - Diagram linking substantive expertise with computer science and statistics is important. Data insights are dependent on close proximity to specialists.&lt;/p&gt;
&lt;p&gt;54:00 - Jim Gray's Fourth Paradigm. Doesn't sound particularly interesting.&lt;/p&gt;
&lt;p&gt;56:00 - Hal Varian's thoughts seem more interesting. I agree with his comments around the need to be able to interpret data and communicate insights derived from data.&lt;/p&gt;
&lt;p&gt;57:40 - The process: Ask, get, explore, model, communicate. AGEMC! Ask, get, explore, model, communicate. AGEMC!&lt;/p&gt;
&lt;p&gt;58:00 - This data science process mimics journalistic inquiry. &lt;/p&gt;
&lt;p&gt;1:03:00 - Hanspeter. CS171 visualisation course sounds tasty.&lt;/p&gt;
&lt;p&gt;1:05:00 - Joe. Stat110 students must be the source of the cheers.&lt;/p&gt;
&lt;p&gt;1:12:00 - Prerequisites are basic computer science and statistic courses. CS is comfortable, but stats might not be. Key aspects of stats mentioned: conditioning, random variables, and famous distributions.&lt;/p&gt;
&lt;p&gt;1:13:00 - Facets: getting data, storing and managing, exploratory, prediction and communication.&lt;/p&gt;
&lt;p&gt;1:17:40 - Frameworks to be used: IPython, pandas, scikit learn, Numpy, Scipy, matplotlib and mrjob. I'll need to pick up scikit learn and mrjob but I'm confident with the rest.&lt;/p&gt;
&lt;p&gt;1:18:00 - Talking about homework. I'm keen to find some local datasets that I might be able to replicate homeworks.&lt;/p&gt;
&lt;p&gt;1:19:00 - Next stop, readings and homework 0.&lt;/p&gt;</summary><category term="harvard"></category><category term="python"></category><category term="cs109"></category></entry><entry><title>Dabbling in data science</title><link href="jackson.gs/dabbling-in-data-science.html" rel="alternate"></link><updated>2014-05-18T13:42:00+10:00</updated><author><name>jacksongs</name></author><id>tag:jackson.gs,2014-05-18:dabbling-in-data-science.html</id><summary type="html">&lt;p&gt;Working as a self-trained data journalist for more than a year, I have developed a set of skills and knowledge that allows me to produce just enough data-driven content to earn my paycheck.&lt;/p&gt;
&lt;p&gt;Specifically these skills are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;knowledge of data sources, &lt;/li&gt;
&lt;li&gt;programming data scrapers,&lt;/li&gt;
&lt;li&gt;proficiency converting and cleaning common data formats,&lt;/li&gt;
&lt;li&gt;data visualisation including map creation, and&lt;/li&gt;
&lt;li&gt;frontend development.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What's missing? That elusive soft skill, analysis, and the framework around it to harden it up.&lt;/p&gt;
&lt;p&gt;Of course there's analysis bubbling away in most of my work. 'Oow look at the jump in the rate for February'. 'Gee those points are concentrated in that location'. But the extent of hypothesis testing in my work has been limited so far.&lt;/p&gt;
&lt;p&gt;So after chatting with an associate, I've decided to seek more formal data analysis skills.&lt;/p&gt;
&lt;p&gt;There appear to be many great, free resources available on the web that promise to teach data science, mining and analysis.&lt;/p&gt;
&lt;p&gt;I have settled on the &lt;a href="http://cs109.org/"&gt;CS109 Data Science course offered by Harvard&lt;/a&gt;. All the lectures are published online, it has an extensive reading list, it seems to be targeted to both undergrad and grad students and it uses Python - my programming language of choice.&lt;/p&gt;
&lt;p&gt;I look forward to sharing my notes and IPython notebooks about the course in coming weeks and months.&lt;/p&gt;</summary><category term="harvard"></category><category term="python"></category><category term="cs109"></category></entry><entry><title>A new Dorne</title><link href="jackson.gs/a-new-dorne.html" rel="alternate"></link><updated>2014-05-05T20:42:00+10:00</updated><author><name>jacksongs</name></author><id>tag:jackson.gs,2014-05-05:a-new-dorne.html</id><summary type="html">&lt;p&gt;As a journalist, the words, pictures and videos I create are my currency.&lt;/p&gt;
&lt;p&gt;In the digital arena words and pictures flitter down news feeds, buried under the weight of watermarked fight scenes and reddit-driven ranting.&lt;/p&gt;
&lt;p&gt;I have blogged before. On Tumblr. On Wordpress. Heck, I'm even a listed contributor to the most excellent Django-based CMS Mezzanine.&lt;/p&gt;
&lt;p&gt;But each platform has proven temporary, mostly because I can't justify the the time required to blog brilliantly.&lt;/p&gt;
&lt;p&gt;But &lt;em&gt;archiving?&lt;/em&gt; Now that's sexy, particularly if I open it to the world.&lt;/p&gt;
&lt;p&gt;I'm going to retain a record of all of my content interesting enough to me to keep in Markdown format and publish it using the Python-powered static site generator Pelican. &lt;/p&gt;
&lt;p&gt;I'm going to store it like I would my high school essays, on file, and, like I would my optimistic attempts to create real-time sports data web projects, on Github.&lt;/p&gt;
&lt;p&gt;I'm choosing Markdown so I can read it with any text editor. It's becoming &lt;a href="http://www.google.com/trends/explore#q=markdown%2C%20microsoft%20word&amp;amp;cmpt=q"&gt;more widely accepted in publishing&lt;/a&gt; after all.&lt;/p&gt;
&lt;p&gt;I'm pursuing the python-powered static site generator Pelican for simplicity.&lt;/p&gt;
&lt;p&gt;Why static? I didn't want a database, but I still wanted to be able to combine an archive with a web framework. &lt;/p&gt;
&lt;p&gt;Having my life's work on a postgres database on a Digital Ocean, Heroku or Webfaction server somewhere didn't appeal - even if I was disciplined about backups.&lt;/p&gt;
&lt;p&gt;On the other hand no one was going to read this post if it was sitting on a folder on my hard drive (apart from government spies).&lt;/p&gt;
&lt;p&gt;I'm a Python person, so Pelican made sense. Plus, Pelican offers great integration with iPython Notebooks. Most importantly, peer pressue is powerful, and dudes like &lt;a href="http://wrobstory.github.io/"&gt;Rob Story&lt;/a&gt; use it.&lt;/p&gt;
&lt;p&gt;So that's that. &lt;/p&gt;
&lt;p&gt;Game of Thrones? Well how else am I going to convince you to read 300 words of drivel? So as not to disappoint, here's a photo of that new dude from Dorne in season four of Game of Thrones, Super Mario*: &lt;/p&gt;
&lt;p&gt;&lt;img alt="Dornish dude" src="http://static.squarespace.com/static/52fc05c9e4b08fc45bd99090/t/534313fce4b00493c5010752/1396904959766/" /&gt;&lt;/p&gt;
&lt;p&gt;*almost certainly not his name.&lt;/p&gt;</summary><category term="pelican"></category><category term="github"></category><category term="wordpress"></category><category term="mezzanine"></category><category term="tumblr"></category><category term="markdown"></category></entry></feed>